{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spell check.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imamol555/ANN/blob/master/spell_check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQrl9iBx5maf",
        "colab_type": "code",
        "outputId": "f56c48b3-cac6-4b68-869d-72979b10a90a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-beta1\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 348.9MB 76kB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 52.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 41.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhFCpX617MJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exHUzvqv7yX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data  = pd.read_excel('generated_mdm_mckesson.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idlvZ9fD8BJq",
        "colab_type": "code",
        "outputId": "71b31bb8-f353-438f-f88b-79d79ea460e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "print(len(data))\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80483\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product</th>\n",
              "      <th>normalized_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>safety vest glowear® 8210hl class 2 2x-large /...</td>\n",
              "      <td>safety vest glowear® 8210hl class 2 2x-large /...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sklar® operating scissors 6-1/2 icncch premium...</td>\n",
              "      <td>sklar® operating scissors 6-1/2 inch premium o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lab jacket valumax® extra-saf bueberrysmalllon...</td>\n",
              "      <td>lab jacket valumax® extra-safe™ blueberry smal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wramu-p jackt esteel gray smalll ong sleeves h...</td>\n",
              "      <td>warm-up jacket steel gray small long sleeves h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>warm-up jac™ket evol,utixon™ blue medmiudm lon...</td>\n",
              "      <td>warm-up jacket evolution™ blue medium long sle...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             product                                 normalized_product\n",
              "0  safety vest glowear® 8210hl class 2 2x-large /...  safety vest glowear® 8210hl class 2 2x-large /...\n",
              "1  sklar® operating scissors 6-1/2 icncch premium...  sklar® operating scissors 6-1/2 inch premium o...\n",
              "2  lab jacket valumax® extra-saf bueberrysmalllon...  lab jacket valumax® extra-safe™ blueberry smal...\n",
              "3  wramu-p jackt esteel gray smalll ong sleeves h...  warm-up jacket steel gray small long sleeves h...\n",
              "4  warm-up jac™ket evol,utixon™ blue medmiudm lon...  warm-up jacket evolution™ blue medium long sle..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4da05zCi8seH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "products = data['product'].to_list()\n",
        "norm_pdcts = data['normalized_product'].to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kdG6POo83nG",
        "colab_type": "code",
        "outputId": "c7fd1bf6-0075-409b-8f61-b588955f13fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.mean([len(pdct) for pdct in products])\n",
        "\n",
        "len(np.max([pdct.split(' ') for pdct in products]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV_4j-EPwx_C",
        "colab_type": "code",
        "outputId": "966e5918-87ba-4b8b-dc17-e613f0cf12fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from numpy.random import shuffle as random_shuffle, seed as random_seed\n",
        "random_seed(123)\n",
        "\n",
        "data = list(zip(products, norm_pdcts ))\n",
        "\n",
        "# shuffle data\n",
        "random_shuffle(data)\n",
        "\n",
        "data = [ item for item in data if len(item[0])<99 and len(item[1])<99]\n",
        "\n",
        "products = [item[0] for item in data]\n",
        "norm_pdcts = [item[1] for item in data]\n",
        "\n",
        "\n",
        "print(len(products))\n",
        "print(len(norm_pdcts))\n",
        "print(products[0])\n",
        "print(norm_pdcts[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50531\n",
            "50531\n",
            "polo shirt 3x-lareg pewet srhort sleeves male\n",
            "polo shirt 3x-large pewter short sleeves male\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjzUVfxPJXAP",
        "colab_type": "text"
      },
      "source": [
        "Remove Unicode symbols "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFJkoluqJWuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "products = list(map(lambda pdct : pdct.encode('ascii', 'ignore').decode(\"utf-8\"), products))\n",
        "norm_pdcts = list(map(lambda pdct : pdct.encode('ascii', 'ignore').decode(\"utf-8\"), norm_pdcts))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RQcd6_QJ5B0",
        "colab_type": "code",
        "outputId": "62fbd28d-9afc-4c2b-f717-083ecffd1235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "for i in range(3):\n",
        "  print(products[i])\n",
        "  print(norm_pdcts[i])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "polo shirt 3x-lareg pewet srhort sleeves male\n",
            "polo shirt 3x-large pewter short sleeves male\n",
            "lab jackeh val(max extr\"-safe ligot 8(nk medium long uleeves hip length\n",
            "lab jacket valumax extra-safe light pink medium long sleeves hip length\n",
            "arm-up jacket pewtr medium log raglan sleevs hip lengh\n",
            "warm-up jacket pewter medium long raglan sleeves hip length\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87MppLke6pON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"\".join(products)\n",
        "chars = list(set(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMTccukR63Yj",
        "colab_type": "code",
        "outputId": "c10f7c75-1ff9-44a1-f629-bdd0b0f2861d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "special_chars = ['<PAD>', '<UNK>', '<GO>', '<EOS>']\n",
        "char_to_ix = { ch:i for i,ch in enumerate( special_chars + sorted(chars)) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate( special_chars + sorted(chars)) }\n",
        "\n",
        "print(ix_to_char)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: '<PAD>', 1: '<UNK>', 2: '<GO>', 3: '<EOS>', 4: ' ', 5: '\"', 6: '%', 7: \"'\", 8: '(', 9: ')', 10: '*', 11: ',', 12: '-', 13: '.', 14: '/', 15: '0', 16: '1', 17: '2', 18: '3', 19: '4', 20: '5', 21: '6', 22: '7', 23: '8', 24: '9', 25: 'a', 26: 'b', 27: 'c', 28: 'd', 29: 'e', 30: 'f', 31: 'g', 32: 'h', 33: 'i', 34: 'j', 35: 'k', 36: 'l', 37: 'm', 38: 'n', 39: 'o', 40: 'p', 41: 'q', 42: 'r', 43: 's', 44: 't', 45: 'u', 46: 'v', 47: 'w', 48: 'x', 49: 'y', 50: 'z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYClh9Ni7slP",
        "colab_type": "code",
        "outputId": "abab13ef-f667-4efb-e9ff-dbc4b3596174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(char_to_ix)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J8UjXwP76Fr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_ids = [[2] + [char_to_ix.get(letter, char_to_ix['<UNK>']) for letter in line] + [3] for line in products]\n",
        "#target_ids = [[char_to_ix.get(letter, char_to_ix['<UNK>']) for letter in line] + [char_to_ix['<EOS>'] for line in norm_pdcts]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJiiq5aS9va2",
        "colab_type": "code",
        "outputId": "fa119f0c-41b5-4ecf-bdac-ee753a2a6c27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "char_to_ix['<EOS>']"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrUc4blR9Dee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_ids = [ [2] + [char_to_ix.get(letter, char_to_ix['<UNK>']) for letter in line] + [3] for line in norm_pdcts]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lblq5Q0n7_8q",
        "colab_type": "code",
        "outputId": "ad24487a-b35f-49c3-85f6-b4afb06c57fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(products[:3])\n",
        "print(source_ids[:3])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['polo shirt 3x-lareg pewet srhort sleeves male', 'lab jackeh val(max extr\"-safe ligot 8(nk medium long uleeves hip length', 'arm-up jacket pewtr medium log raglan sleevs hip lengh']\n",
            "[[2, 40, 39, 36, 39, 4, 43, 32, 33, 42, 44, 4, 18, 48, 12, 36, 25, 42, 29, 31, 4, 40, 29, 47, 29, 44, 4, 43, 42, 32, 39, 42, 44, 4, 43, 36, 29, 29, 46, 29, 43, 4, 37, 25, 36, 29, 3], [2, 36, 25, 26, 4, 34, 25, 27, 35, 29, 32, 4, 46, 25, 36, 8, 37, 25, 48, 4, 29, 48, 44, 42, 5, 12, 43, 25, 30, 29, 4, 36, 33, 31, 39, 44, 4, 23, 8, 38, 35, 4, 37, 29, 28, 33, 45, 37, 4, 36, 39, 38, 31, 4, 45, 36, 29, 29, 46, 29, 43, 4, 32, 33, 40, 4, 36, 29, 38, 31, 44, 32, 3], [2, 25, 42, 37, 12, 45, 40, 4, 34, 25, 27, 35, 29, 44, 4, 40, 29, 47, 44, 42, 4, 37, 29, 28, 33, 45, 37, 4, 36, 39, 31, 4, 42, 25, 31, 36, 25, 38, 4, 43, 36, 29, 29, 46, 43, 4, 32, 33, 40, 4, 36, 29, 38, 31, 32, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc3F04fO8D7L",
        "colab_type": "code",
        "outputId": "2de3fc97-8626-4d7d-fdbe-cae00e94ad25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print('max :' , len(max(source_ids, key=len)))\n",
        "print('min :' , len(min(source_ids, key=len)))\n",
        "\n",
        "print('max :' , len(max(target_ids, key=len)))\n",
        "print('min :' , len(min(target_ids, key=len)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max : 100\n",
            "min : 16\n",
            "max : 100\n",
            "min : 17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDF_rmUky-g-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot9l0j9zzQ9z",
        "colab_type": "code",
        "outputId": "dcaa128d-b97c-4b62-fb96-13cd7240ab23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "lengths = [len(pdct) for pdct in products]\n",
        "\n",
        "plt.hist(lengths)\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5Ybf8c0Q-ZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded_source = [ pdct + [0]*(100 - len(pdct)) for pdct in source_ids]\n",
        "padded_target = [ pdct + [0]*(100 - len(pdct)) for pdct in target_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIDZ2bJuLN2Y",
        "colab_type": "code",
        "outputId": "93357eef-386a-4b83-d01b-0c4060d5177c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = np.array([np.array(pdct).reshape(100,1) for pdct in padded_source])\n",
        "X.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50531, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0IfMIdmSK7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = np.array([np.array(pdct).reshape(100,1) for pdct in padded_target])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "685UoER-R7cl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.squeeze(X)\n",
        "y = np.squeeze(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiNmHKrj-Aih",
        "colab_type": "code",
        "outputId": "df0aa577-e904-4878-b741-59375b9cd192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "X[:3]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2, 40, 39, 36, 39,  4, 43, 32, 33, 42, 44,  4, 18, 48, 12, 36,\n",
              "        25, 42, 29, 31,  4, 40, 29, 47, 29, 44,  4, 43, 42, 32, 39, 42,\n",
              "        44,  4, 43, 36, 29, 29, 46, 29, 43,  4, 37, 25, 36, 29,  3,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0],\n",
              "       [ 2, 36, 25, 26,  4, 34, 25, 27, 35, 29, 32,  4, 46, 25, 36,  8,\n",
              "        37, 25, 48,  4, 29, 48, 44, 42,  5, 12, 43, 25, 30, 29,  4, 36,\n",
              "        33, 31, 39, 44,  4, 23,  8, 38, 35,  4, 37, 29, 28, 33, 45, 37,\n",
              "         4, 36, 39, 38, 31,  4, 45, 36, 29, 29, 46, 29, 43,  4, 32, 33,\n",
              "        40,  4, 36, 29, 38, 31, 44, 32,  3,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0],\n",
              "       [ 2, 25, 42, 37, 12, 45, 40,  4, 34, 25, 27, 35, 29, 44,  4, 40,\n",
              "        29, 47, 44, 42,  4, 37, 29, 28, 33, 45, 37,  4, 36, 39, 31,  4,\n",
              "        42, 25, 31, 36, 25, 38,  4, 43, 36, 29, 29, 46, 43,  4, 32, 33,\n",
              "        40,  4, 36, 29, 38, 31, 32,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VipXnGGRJnqO",
        "colab_type": "code",
        "outputId": "a865fcf9-a87e-475f-8a65-1f01986607ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "y[:3]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2, 40, 39, 36, 39,  4, 43, 32, 33, 42, 44,  4, 18, 48, 12, 36,\n",
              "        25, 42, 31, 29,  4, 40, 29, 47, 44, 29, 42,  4, 43, 32, 39, 42,\n",
              "        44,  4, 43, 36, 29, 29, 46, 29, 43,  4, 37, 25, 36, 29,  3,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0],\n",
              "       [ 2, 36, 25, 26,  4, 34, 25, 27, 35, 29, 44,  4, 46, 25, 36, 45,\n",
              "        37, 25, 48,  4, 29, 48, 44, 42, 25, 12, 43, 25, 30, 29,  4, 36,\n",
              "        33, 31, 32, 44,  4, 40, 33, 38, 35,  4, 37, 29, 28, 33, 45, 37,\n",
              "         4, 36, 39, 38, 31,  4, 43, 36, 29, 29, 46, 29, 43,  4, 32, 33,\n",
              "        40,  4, 36, 29, 38, 31, 44, 32,  3,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0],\n",
              "       [ 2, 47, 25, 42, 37, 12, 45, 40,  4, 34, 25, 27, 35, 29, 44,  4,\n",
              "        40, 29, 47, 44, 29, 42,  4, 37, 29, 28, 33, 45, 37,  4, 36, 39,\n",
              "        38, 31,  4, 42, 25, 31, 36, 25, 38,  4, 43, 36, 29, 29, 46, 29,\n",
              "        43,  4, 32, 33, 40,  4, 36, 29, 38, 31, 44, 32,  3,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vqpFarOSmXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X[:500]\n",
        "y = y[:500]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s_WoDb7POmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((X, y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_aArTsPQbVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UJg1Pq5Qiy2",
        "colab_type": "code",
        "outputId": "9d0d0bf1-3c64-42b5-89ce-5ec8840828c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 100]), TensorShape([64, 100]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qnLrg0QTvuY",
        "colab_type": "text"
      },
      "source": [
        "#Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0idYuaYTub6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgxkXjhsT8l2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 128\n",
        "vocab_inp_size = len(char_to_ix)\n",
        "vocab_tar_size = len(char_to_ix)\n",
        "units = 32\n",
        "\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkvGR0GvVMcP",
        "colab_type": "code",
        "outputId": "294cc371-79d3-4c9f-d78b-f781c804f2ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 100, 32)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gbLjRXR4GDD",
        "colab_type": "code",
        "outputId": "22ec858a-219f-4364-dbc2-48b487d6ad38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "encoder.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  6528      \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    multiple                  15552     \n",
            "=================================================================\n",
            "Total params: 22,080\n",
            "Trainable params: 22,080\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V8-La9_VSnX",
        "colab_type": "text"
      },
      "source": [
        "#Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-Sfk1_cVVUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # to perform addition to calculate the score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60A1K4A6VZvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbpulBCyVtQk",
        "colab_type": "code",
        "outputId": "6c381f7a-2e89-4ebb-c2e4-8465b7a8be12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 32)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 100, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QUKp8Ns4OT1",
        "colab_type": "code",
        "outputId": "1c9bfbf4-72a0-4863-a13a-500460146e2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "attention_layer.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"bahdanau_attention\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                multiple                  330       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  330       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  11        \n",
            "=================================================================\n",
            "Total params: 671\n",
            "Trainable params: 671\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqF9Dfe1V3MZ",
        "colab_type": "text"
      },
      "source": [
        "#Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFXll65YV6av",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ31MwAnV90K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY8PnDy2WI1_",
        "colab_type": "code",
        "outputId": "a47c9889-8f2c-4a26-8d18-45466b1292b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 51)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILWubObZ4Udf",
        "colab_type": "code",
        "outputId": "b1f72ec5-f168-4b52-f8a6-7fedc309293a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "decoder.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      multiple                  6528      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  multiple                  18624     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  1683      \n",
            "_________________________________________________________________\n",
            "bahdanau_attention_1 (Bahdan multiple                  2145      \n",
            "=================================================================\n",
            "Total params: 28,980\n",
            "Trainable params: 28,980\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ8JZ18TV6Dh",
        "colab_type": "text"
      },
      "source": [
        "##Optimizer and Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Graf67cOW7oL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkIi2vyKXAW8",
        "colab_type": "text"
      },
      "source": [
        "##Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDi4pm-6XDC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2AZ1_3cXhfK",
        "colab_type": "text"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT2dSv9dXjQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([char_to_ix['<GO>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib0bc_ZvYAgk",
        "colab_type": "code",
        "outputId": "b886b639-9595-447a-8b54-94dbf58bbfe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "steps_per_epoch = len(padded_source[:500])//BATCH_SIZE\n",
        "steps_per_epoch"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKfa-N4wYiaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp1KBScFYPEe",
        "colab_type": "code",
        "outputId": "e0dde37a-110e-4cf8-9d3e-4595e394f426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 0.7203\n",
            "Time taken for 1 epoch 1.6355745792388916 sec\n",
            "\n",
            "Epoch 2 Loss 0.9393\n",
            "Time taken for 1 epoch 1.5537619590759277 sec\n",
            "\n",
            "Epoch 3 Loss 1.1125\n",
            "Time taken for 1 epoch 1.5140221118927002 sec\n",
            "\n",
            "Epoch 4 Loss 1.0261\n",
            "Time taken for 1 epoch 1.5331730842590332 sec\n",
            "\n",
            "Epoch 5 Loss 0.9688\n",
            "Time taken for 1 epoch 1.5161371231079102 sec\n",
            "\n",
            "Epoch 6 Loss 0.9229\n",
            "Time taken for 1 epoch 1.5145063400268555 sec\n",
            "\n",
            "Epoch 7 Loss 0.8951\n",
            "Time taken for 1 epoch 1.4942119121551514 sec\n",
            "\n",
            "Epoch 8 Loss 0.8699\n",
            "Time taken for 1 epoch 1.5013983249664307 sec\n",
            "\n",
            "Epoch 9 Loss 0.8493\n",
            "Time taken for 1 epoch 1.5240273475646973 sec\n",
            "\n",
            "Epoch 10 Loss 0.8377\n",
            "Time taken for 1 epoch 1.5023283958435059 sec\n",
            "\n",
            "Epoch 11 Loss 0.8272\n",
            "Time taken for 1 epoch 1.4815220832824707 sec\n",
            "\n",
            "Epoch 12 Loss 0.8170\n",
            "Time taken for 1 epoch 1.4996984004974365 sec\n",
            "\n",
            "Epoch 13 Loss 0.8057\n",
            "Time taken for 1 epoch 1.4945669174194336 sec\n",
            "\n",
            "Epoch 14 Loss 0.7985\n",
            "Time taken for 1 epoch 1.5185565948486328 sec\n",
            "\n",
            "Epoch 15 Loss 0.7926\n",
            "Time taken for 1 epoch 1.4742374420166016 sec\n",
            "\n",
            "Epoch 16 Loss 0.7873\n",
            "Time taken for 1 epoch 1.4996204376220703 sec\n",
            "\n",
            "Epoch 17 Loss 0.7839\n",
            "Time taken for 1 epoch 1.471266746520996 sec\n",
            "\n",
            "Epoch 18 Loss 0.7818\n",
            "Time taken for 1 epoch 1.4940605163574219 sec\n",
            "\n",
            "Epoch 19 Loss 0.7803\n",
            "Time taken for 1 epoch 1.491816759109497 sec\n",
            "\n",
            "Epoch 20 Loss 0.7770\n",
            "Time taken for 1 epoch 1.5016753673553467 sec\n",
            "\n",
            "Epoch 21 Loss 0.7746\n",
            "Time taken for 1 epoch 1.5151660442352295 sec\n",
            "\n",
            "Epoch 22 Loss 0.7689\n",
            "Time taken for 1 epoch 1.605891227722168 sec\n",
            "\n",
            "Epoch 23 Loss 0.7632\n",
            "Time taken for 1 epoch 1.5960254669189453 sec\n",
            "\n",
            "Epoch 24 Loss 0.7605\n",
            "Time taken for 1 epoch 1.6353833675384521 sec\n",
            "\n",
            "Epoch 25 Loss 0.7572\n",
            "Time taken for 1 epoch 1.6062557697296143 sec\n",
            "\n",
            "Epoch 26 Loss 0.7569\n",
            "Time taken for 1 epoch 1.6314222812652588 sec\n",
            "\n",
            "Epoch 27 Loss 0.7542\n",
            "Time taken for 1 epoch 1.6128900051116943 sec\n",
            "\n",
            "Epoch 28 Loss 0.7505\n",
            "Time taken for 1 epoch 1.5221409797668457 sec\n",
            "\n",
            "Epoch 29 Loss 0.7483\n",
            "Time taken for 1 epoch 1.5018322467803955 sec\n",
            "\n",
            "Epoch 30 Loss 0.7458\n",
            "Time taken for 1 epoch 1.5102441310882568 sec\n",
            "\n",
            "Epoch 31 Loss 0.7450\n",
            "Time taken for 1 epoch 1.4771699905395508 sec\n",
            "\n",
            "Epoch 32 Loss 0.7422\n",
            "Time taken for 1 epoch 1.5014572143554688 sec\n",
            "\n",
            "Epoch 33 Loss 0.7402\n",
            "Time taken for 1 epoch 1.4779150485992432 sec\n",
            "\n",
            "Epoch 34 Loss 0.7378\n",
            "Time taken for 1 epoch 1.5025722980499268 sec\n",
            "\n",
            "Epoch 35 Loss 0.7364\n",
            "Time taken for 1 epoch 1.4731175899505615 sec\n",
            "\n",
            "Epoch 36 Loss 0.7341\n",
            "Time taken for 1 epoch 1.4968416690826416 sec\n",
            "\n",
            "Epoch 37 Loss 0.7315\n",
            "Time taken for 1 epoch 1.4781410694122314 sec\n",
            "\n",
            "Epoch 38 Loss 0.7302\n",
            "Time taken for 1 epoch 1.5057499408721924 sec\n",
            "\n",
            "Epoch 39 Loss 0.7294\n",
            "Time taken for 1 epoch 1.4998714923858643 sec\n",
            "\n",
            "Epoch 40 Loss 0.7259\n",
            "Time taken for 1 epoch 1.506176471710205 sec\n",
            "\n",
            "Epoch 41 Loss 0.7247\n",
            "Time taken for 1 epoch 1.4919319152832031 sec\n",
            "\n",
            "Epoch 42 Loss 0.7247\n",
            "Time taken for 1 epoch 1.4920296669006348 sec\n",
            "\n",
            "Epoch 43 Loss 0.7225\n",
            "Time taken for 1 epoch 1.4591703414916992 sec\n",
            "\n",
            "Epoch 44 Loss 0.7204\n",
            "Time taken for 1 epoch 1.5059869289398193 sec\n",
            "\n",
            "Epoch 45 Loss 0.7185\n",
            "Time taken for 1 epoch 1.4697039127349854 sec\n",
            "\n",
            "Epoch 46 Loss 0.7177\n",
            "Time taken for 1 epoch 1.5030949115753174 sec\n",
            "\n",
            "Epoch 47 Loss 0.7163\n",
            "Time taken for 1 epoch 1.472447156906128 sec\n",
            "\n",
            "Epoch 48 Loss 0.7153\n",
            "Time taken for 1 epoch 1.5056633949279785 sec\n",
            "\n",
            "Epoch 49 Loss 0.7126\n",
            "Time taken for 1 epoch 1.5080392360687256 sec\n",
            "\n",
            "Epoch 50 Loss 0.7258\n",
            "Time taken for 1 epoch 1.503223180770874 sec\n",
            "\n",
            "Epoch 51 Loss 0.7311\n",
            "Time taken for 1 epoch 1.476914644241333 sec\n",
            "\n",
            "Epoch 52 Loss 0.7211\n",
            "Time taken for 1 epoch 1.5108366012573242 sec\n",
            "\n",
            "Epoch 53 Loss 0.7204\n",
            "Time taken for 1 epoch 1.4741716384887695 sec\n",
            "\n",
            "Epoch 54 Loss 0.7149\n",
            "Time taken for 1 epoch 1.5217373371124268 sec\n",
            "\n",
            "Epoch 55 Loss 0.7111\n",
            "Time taken for 1 epoch 1.498215913772583 sec\n",
            "\n",
            "Epoch 56 Loss 0.7075\n",
            "Time taken for 1 epoch 1.5022237300872803 sec\n",
            "\n",
            "Epoch 57 Loss 0.7038\n",
            "Time taken for 1 epoch 1.479325294494629 sec\n",
            "\n",
            "Epoch 58 Loss 0.7017\n",
            "Time taken for 1 epoch 1.507199764251709 sec\n",
            "\n",
            "Epoch 59 Loss 0.7038\n",
            "Time taken for 1 epoch 1.5592257976531982 sec\n",
            "\n",
            "Epoch 60 Loss 0.7033\n",
            "Time taken for 1 epoch 1.5777678489685059 sec\n",
            "\n",
            "Epoch 61 Loss 0.7002\n",
            "Time taken for 1 epoch 1.542931318283081 sec\n",
            "\n",
            "Epoch 62 Loss 0.6969\n",
            "Time taken for 1 epoch 1.555093765258789 sec\n",
            "\n",
            "Epoch 63 Loss 0.6947\n",
            "Time taken for 1 epoch 1.4737906455993652 sec\n",
            "\n",
            "Epoch 64 Loss 0.6930\n",
            "Time taken for 1 epoch 1.5083036422729492 sec\n",
            "\n",
            "Epoch 65 Loss 0.6916\n",
            "Time taken for 1 epoch 1.472595453262329 sec\n",
            "\n",
            "Epoch 66 Loss 0.6899\n",
            "Time taken for 1 epoch 1.4961504936218262 sec\n",
            "\n",
            "Epoch 67 Loss 0.6888\n",
            "Time taken for 1 epoch 1.473783016204834 sec\n",
            "\n",
            "Epoch 68 Loss 0.6872\n",
            "Time taken for 1 epoch 1.4927120208740234 sec\n",
            "\n",
            "Epoch 69 Loss 0.6866\n",
            "Time taken for 1 epoch 1.49214506149292 sec\n",
            "\n",
            "Epoch 70 Loss 0.6857\n",
            "Time taken for 1 epoch 1.5073800086975098 sec\n",
            "\n",
            "Epoch 71 Loss 0.6845\n",
            "Time taken for 1 epoch 1.4749233722686768 sec\n",
            "\n",
            "Epoch 72 Loss 0.6858\n",
            "Time taken for 1 epoch 1.488330602645874 sec\n",
            "\n",
            "Epoch 73 Loss 0.6841\n",
            "Time taken for 1 epoch 1.4621245861053467 sec\n",
            "\n",
            "Epoch 74 Loss 0.6838\n",
            "Time taken for 1 epoch 1.4861712455749512 sec\n",
            "\n",
            "Epoch 75 Loss 0.6830\n",
            "Time taken for 1 epoch 1.4848647117614746 sec\n",
            "\n",
            "Epoch 76 Loss 0.6820\n",
            "Time taken for 1 epoch 1.4896283149719238 sec\n",
            "\n",
            "Epoch 77 Loss 0.6788\n",
            "Time taken for 1 epoch 1.4659042358398438 sec\n",
            "\n",
            "Epoch 78 Loss 0.6776\n",
            "Time taken for 1 epoch 1.5019910335540771 sec\n",
            "\n",
            "Epoch 79 Loss 0.6767\n",
            "Time taken for 1 epoch 1.4744243621826172 sec\n",
            "\n",
            "Epoch 80 Loss 0.6789\n",
            "Time taken for 1 epoch 1.512096643447876 sec\n",
            "\n",
            "Epoch 81 Loss 0.6897\n",
            "Time taken for 1 epoch 1.473841905593872 sec\n",
            "\n",
            "Epoch 82 Loss 0.6866\n",
            "Time taken for 1 epoch 1.499847412109375 sec\n",
            "\n",
            "Epoch 83 Loss 0.6848\n",
            "Time taken for 1 epoch 1.473937749862671 sec\n",
            "\n",
            "Epoch 84 Loss 0.6801\n",
            "Time taken for 1 epoch 1.5032048225402832 sec\n",
            "\n",
            "Epoch 85 Loss 0.6793\n",
            "Time taken for 1 epoch 1.4753444194793701 sec\n",
            "\n",
            "Epoch 86 Loss 0.6761\n",
            "Time taken for 1 epoch 1.5133781433105469 sec\n",
            "\n",
            "Epoch 87 Loss 0.6994\n",
            "Time taken for 1 epoch 1.462463617324829 sec\n",
            "\n",
            "Epoch 88 Loss 0.6915\n",
            "Time taken for 1 epoch 1.4937961101531982 sec\n",
            "\n",
            "Epoch 89 Loss 0.6802\n",
            "Time taken for 1 epoch 1.4638853073120117 sec\n",
            "\n",
            "Epoch 90 Loss 0.6754\n",
            "Time taken for 1 epoch 1.5113418102264404 sec\n",
            "\n",
            "Epoch 91 Loss 0.6715\n",
            "Time taken for 1 epoch 1.489738941192627 sec\n",
            "\n",
            "Epoch 92 Loss 0.6781\n",
            "Time taken for 1 epoch 1.4864294528961182 sec\n",
            "\n",
            "Epoch 93 Loss 0.6748\n",
            "Time taken for 1 epoch 1.4690892696380615 sec\n",
            "\n",
            "Epoch 94 Loss 0.6676\n",
            "Time taken for 1 epoch 1.4960250854492188 sec\n",
            "\n",
            "Epoch 95 Loss 0.6641\n",
            "Time taken for 1 epoch 1.469580888748169 sec\n",
            "\n",
            "Epoch 96 Loss 0.6628\n",
            "Time taken for 1 epoch 1.499896764755249 sec\n",
            "\n",
            "Epoch 97 Loss 0.6606\n",
            "Time taken for 1 epoch 1.470193862915039 sec\n",
            "\n",
            "Epoch 98 Loss 0.6587\n",
            "Time taken for 1 epoch 1.5031976699829102 sec\n",
            "\n",
            "Epoch 99 Loss 0.6578\n",
            "Time taken for 1 epoch 1.4600114822387695 sec\n",
            "\n",
            "Epoch 100 Loss 0.6580\n",
            "Time taken for 1 epoch 1.4926681518554688 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0gLxYcglDgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length_targ = max_length_inp = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG6s_gwbnwYz",
        "colab_type": "code",
        "outputId": "509124dd-c904-4f41-f23a-ecdd2b385d06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  sentence = sentence.encode('ascii', 'ignore').decode(\"utf-8\")\n",
        "  sent_ids = [2]  + [char_to_ix.get(letter, char_to_ix['<UNK>']) for letter in sentence] + [3] \n",
        "  padded_sentence = sent_ids + [0]*(100 - len(sent_ids))\n",
        "  inputs = tf.convert_to_tensor(padded_sentence)\n",
        "  print(inputs.shape)\n",
        "  inputs = tf.expand_dims(inputs, 0)\n",
        "  print(inputs.shape)\n",
        "  return inputs\n",
        "\n",
        "\n",
        "preprocess_sentence('polo shirt mediu mblac kshrot sleeves female')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100,)\n",
            "(1, 100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=245496, shape=(1, 100), dtype=int32, numpy=\n",
              "array([[ 2, 40, 39, 36, 39,  4, 43, 32, 33, 42, 44,  4, 37, 29, 28, 33,\n",
              "        45,  4, 37, 26, 36, 25, 27,  4, 35, 43, 32, 42, 39, 44,  4, 43,\n",
              "        36, 29, 29, 46, 29, 43,  4, 30, 29, 37, 25, 36, 29,  3,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0UJj6Hm4xoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "\n",
        "    inputs = preprocess_sentence(sentence)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([char_to_ix['<GO>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "      \n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += ix_to_char[predicted_id] + ' '\n",
        "\n",
        "        if ix_to_char[predicted_id] == '<EOS>':\n",
        "            return result, sentence\n",
        "\n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrHAsQKgpgzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def spell_check(sentence):\n",
        "    result, sentence = evaluate(sentence)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNEWq-c-pkCm",
        "colab_type": "text"
      },
      "source": [
        "#Restore Checkpoint and spell check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_2vZOuEpjE9",
        "colab_type": "code",
        "outputId": "86127f17-6322-4e93-d97c-bd3ed8ba1d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3b3c6c2d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkPslm43sWqo",
        "colab_type": "code",
        "outputId": "4040c444-8cd0-48c4-bb00-d9b58a761b73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "spell_check('warm-up jaecket evoluttion™ blueh large l5ong sleeves hip (len1gth')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100,)\n",
            "(1, 100)\n",
            "Input: warm-up jaecket evoluttion™ blueh large l5ong sleeves hip (len1gth\n",
            "Predicted translation: w a r m - u p   j a c k e t   b l u e   l o n g   s l e e v e s   h i p   l e n g t h <EOS> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMfVjzgoqjQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9faqZVujjgS9",
        "colab_type": "code",
        "outputId": "67386340-be06-47ad-b52a-6a266e28d5bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs7ayjcejhsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -a /content/training_checkpoints '/content/drive/My Drive/programs/latest'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGTGacd2kKxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}